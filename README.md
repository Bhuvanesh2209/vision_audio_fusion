# Vision-Audio Fusion System ğŸ¥ğŸ”Š

A dual-modality object detection system that intelligently switches between **YOLOv8 (vision)** and **OpenL3 (audio)** models to identify objects in video clips based on lighting conditions.

> âš¡ï¸ In good lighting â†’ Vision-based detection using YOLOv8  
> ğŸŒ™ In poor lighting â†’ Audio-based classification using OpenL3 embeddings

---

## ğŸ“Œ Project Overview

This project addresses real-world limitations in object detection under poor visual conditions (e.g., night scenes, fog, motion blur) by leveraging audio cues when vision fails.

It performs:
- Object detection from video frames using YOLOv8
- Audio classification using OpenL3 embeddings
- Lighting analysis to choose the optimal modality
- CSV output of all predictions

---

## ğŸ§  Architecture

```text
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Frame.jpg   â”‚
           â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
       Bright? â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        (cv2)    â”‚            â”‚
          Yes    â†“            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Use YOLOv8   â”‚  â”‚ Use OpenL3     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚             â”‚
            Detected        Embeddings
             Objects           â”‚
                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
            Save predictions
ğŸ“ Directory Structure
bash
Copy
Edit
vision_audio_fusion/
â”‚
â”œâ”€â”€ frames/                # Extracted video frames (JPG)
â”œâ”€â”€ audio/                 # Extracted audio clips (WAV)
â”œâ”€â”€ main.py                # Run detection pipeline
â”œâ”€â”€ extract_data.py        # Feature extraction logic
â””â”€â”€ predictions.csv        # Output predictions
âš™ï¸ Requirements
Install dependencies inside a virtual environment:

bash
Copy
Edit
python -m venv cv
source cv/bin/activate
pip install -r requirements.txt
Minimal requirements.txt:

txt
Copy
Edit
ultralytics
openl3
librosa
soundfile
tensorflow
numpy
opencv-python
ğŸš€ Usage
1. Extract frames and audio (if not already):
bash
Copy
Edit
# Add videos and extract frames + audio using your own script/tool
2. Train the model
bash
Copy
Edit
python train.py
3. Predict with a new sample
bash
Copy
Edit
python predict.py frames/sample_frame.jpg audio/sample.wav
4. Run entire pipeline on dataset
bash
Copy
Edit
python main.py
ğŸ§ª Example Output
rust
Copy
Edit
Good lighting in sample1.jpg -> using YOLOv8
sample1 -> ['car', 'person']

Poor lighting in sample2.jpg -> using audio
sample2 -> ['truck', 'ambient']
